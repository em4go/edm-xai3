---
title: "xAI 3"
author:
  - name: "Laiqian Ji"
  - name: "Ernesto Martínez"
  - name: "Álvaro Prado Expóstio"
format: html
---

# XAI: Interpretable Models 3

```{r}
library(readr)
library(dplyr)
library(lubridate)
library(ranger) # For Random Forest
library(pdp)    # For Partial Dependence Plots
library(ggplot2) # For plotting

SEED <- 1234 # Set seed for reproducibility
```


## Exercise 1: One-dimensional Partial Dependence Plot (Bike Rentals - day.csv)

### Loading and preprocessing

We'll use slightly the same preprocessing as in the previous xAI task for the bike rentals dataset.

```{r}
# Load data
bike_data_day <- read_csv("data/day.csv")

# Preprocessing (based on your script)
bike_data_day <- bike_data_day %>%
  mutate(
    spring = ifelse(season == 1, 1, 0),
    summer = ifelse(season == 2, 1, 0),
    fall = ifelse(season == 3, 1, 0)
  )

bike_data_day <- bike_data_day %>%
  mutate(
    MISTY = ifelse(weathersit == 2, 1, 0),
    RAIN = ifelse(weathersit %in% c(3, 4), 1, 0) # Assuming 4 is also bad weather
  )

bike_data_day <- bike_data_day %>%
  mutate(
    temp_scaled = temp * 41,       # Actual temperature in Celsius
    hum_scaled = hum * 100,        # Actual humidity in %
    windspeed_scaled = windspeed * 67 # Actual windspeed
  )

bike_data_day <- bike_data_day %>%
  mutate(
    dteday = as.Date(dteday),
    days_since_2011 = as.numeric(difftime(dteday, as.Date("2011-01-01"), units = "days"))
  )

# Select features for the model
# Note: We use the scaled versions of temp, hum, windspeed for easier interpretation
model_data_day <- bike_data_day %>%
  select(
    cnt, workingday, holiday, spring, summer, fall, MISTY, RAIN,
    temp_scaled, hum_scaled, windspeed_scaled, days_since_2011
  )

# Convert logicals/numerics that should be factors (if any, for RF)
# For ranger, it can often handle numeric 0/1s, but explicit factors can be clearer.
# For simplicity here, we'll let ranger handle them.
# Ensure no missing values, or handle them (e.g., imputation)
print(paste("Missing values in model_data_day:", sum(is.na(model_data_day))))
model_data_day <- na.omit(model_data_day) # Simple NA removal

```

### Fit random forest model


```{r}
# Fit Random Forest model
# Using ranger for efficiency. Using default mtry and 500 trees.
set.seed(SEED) # for reproducibility
rf_model_day <- ranger(
  formula = cnt ~ .,
  data = model_data_day,
  num.trees = 500,
  importance = 'permutation' # Good to have for general feature importance
)

print(rf_model_day)
```

### Generate and Visualize 1D PDPs

We'll generate PDPs for days_since_2011, temp_scaled, hum_scaled, and windspeed_scaled.


```{r}
# Features for PDP
features_to_plot_day <- c("days_since_2011", "temp_scaled", "hum_scaled", "windspeed_scaled")

# Generate and plot PDPs
for (feature in features_to_plot_day) {
  cat("Processing feature:", feature, "\n") # For debugging

  # Generate partial dependence data
  pdp_obj <- NULL # Initialize to ensure it's fresh each iteration
  tryCatch({
    pdp_obj <- partial(rf_model_day,
                       pred.var = feature,
                       plot = FALSE, # Important: we want data, not an immediate plot
                       train = model_data_day)
    cat("Successfully created pdp_obj for", feature, "\n")
    # print(head(pdp_obj)) # Optional: uncomment to inspect pdp_obj
  }, error = function(e) {
    cat("Error in partial() for feature", feature, ":", e$message, "\n")
  })

  if (!is.null(pdp_obj)) {
    # Try plotting using autoplot first
    p <- NULL # Initialize p
    tryCatch({
      # autoplot is often more robust for pdp objects
      p <- autoplot(pdp_obj, rug = TRUE, train = model_data_day) +
        ylab("Predicted Bike Count (cnt)") +
        ggtitle(paste("PDP for", feature)) +
        theme_minimal() # Added a theme for better default appearance
      print(p)
      cat("Successfully plotted with autoplot for", feature, "\n")
    }, error = function(e_autoplot) {
      cat("Error using autoplot for feature", feature, ":", e_autoplot$message, "\n")
      cat("Attempting with plotPartial as a fallback...\n")
      # Fallback to plotPartial if autoplot fails, but isolate its call
      plot_base <- NULL
      tryCatch({
          plot_base <- plotPartial(pdp_obj, rug = TRUE, train = model_data_day)
          # Check if plot_base is a ggplot object
          if (inherits(plot_base, "ggplot")) {
              p <- plot_base +
                ylab("Predicted Bike Count (cnt)") +
                ggtitle(paste("PDP for", feature)) +
                theme_minimal()
              print(p)
              cat("Successfully plotted with plotPartial for", feature, "\n")
          } else {
              cat("plotPartial did not return a ggplot object for", feature, ". Class was:", class(plot_base), "\n")
          }
      }, error = function(e_plotpartial) {
          cat("Error in plotPartial() for feature", feature, ":", e_plotpartial$message, "\n")
      })
    })
  } else {
    cat("Skipping plot for", feature, "due to error in partial().\n")
  }
  cat("------------------------------------\n") # Separator
}
```



## Exercise 2: Bidimensional Partial Dependency Plot (Bike Rentals - hour.csv)

### Data loading and preprocessing

```{r}
bike_data_hour_full <- read_csv("data/hour.csv")

# Preprocessing
# Scale temp, hum, windspeed similar to day.csv for consistency
# Original values in hour.csv for temp, atemp, hum, windspeed are normalized (0-1)
bike_data_hour_processed <- bike_data_hour_full %>%
  mutate(
    temp_scaled = temp * 41,       # Actual temperature in Celsius
    hum_scaled = hum * 100,        # Actual humidity in %
    windspeed_scaled = windspeed * 67, # Actual windspeed
    # Create categorical season and weather if needed for the model,
    # or use them as is if ranger handles them well.
    # For PDP, we only need temp_scaled, hum_scaled, and other predictors.
    season = factor(season),
    weathersit = factor(weathersit),
    holiday = factor(holiday),
    workingday = factor(workingday),
    weekday = factor(weekday),
    yr = factor(yr) # yr is 0 or 1, can be a factor or numeric
  )

# Select features for the model.
# Include relevant features that might influence bike count.
model_features_hour <- c(
    "cnt", "season", "yr", "mnth", "hr", "holiday", "weekday",
    "workingday", "weathersit", "temp_scaled", "hum_scaled", "windspeed_scaled"
)
model_data_hour_processed <- bike_data_hour_processed %>%
  select(all_of(model_features_hour))

# Handle missing values (if any)
print(paste("Missing values in model_data_hour_processed:", sum(is.na(model_data_hour_processed))))
model_data_hour_processed <- na.omit(model_data_hour_processed)
```

### Random sampling to reduce the amount of data (1000 rows)

```{r}
model_data_hour_processed
```



```{r}
set.seed(SEED) # for reproducibility
sample_size_hour <- 1000
n_total_rows_hour <- nrow(model_data_hour_processed)

if (n_total_rows_hour > sample_size_hour) {
  # Determine the latest possible starting point for a contiguous block
  max_start_index <- n_total_rows_hour - sample_size_hour + 1

  # Randomly select a starting index for the block
  # Ensure max_start_index is at least 1
  if (max_start_index < 1) {
      max_start_index <- 1 # Should not happen if n_total_rows_hour > sample_size_hour
  }
  start_index <- sample(1:max_start_index, 1)

  # Extract the contiguous block of rows
  model_data_hour_sample <- model_data_hour_processed[start_index:(start_index + sample_size_hour - 1), ]

  cat("Sampled a contiguous block of", sample_size_hour, "rows, starting at index", start_index, "\n")
  cat("Time range of sample (based on first and last 'instant' if available, or row numbers):\n")
  # If you have 'dteday' and 'hr' in model_data_hour_sample, you can print their range
  # For example, if 'instant' is still in bike_data_hour_full and corresponds to rows:
  # first_instant_in_sample <- bike_data_hour_full$instant[start_index]
  # last_instant_in_sample <- bike_data_hour_full$instant[start_index + sample_size_hour - 1]
  # cat("Instant range:", first_instant_in_sample, "to", last_instant_in_sample, "\n")

} else {
  # If the total number of rows is less than or equal to the sample size, use all data
  model_data_hour_sample <- model_data_hour_processed
  cat("Using all", n_total_rows_hour, "rows as sample size is not smaller.\n")
}

# Verify the dimensions of the sample
print(dim(model_data_hour_sample))
```


```{r}
set.seed(SEED)
rf_model_hour <- ranger(
  formula = cnt ~ .,
  data = model_data_hour_sample,
  num.trees = 500,
  importance = 'permutation'
)
print(rf_model_hour)
```


```{r}
# Generate 2D PDP for humidity and temperature
pdp_2d_hour <- partial(
  rf_model_hour,
  pred.var = c("temp_scaled", "hum_scaled"),
  plot = FALSE,
  train = model_data_hour_sample,
  chull = TRUE # Computes PDP only within the convex hull of training data for these two features
)

```

```{r}
# Determine tile width and height for geom_tile
# This calculation assumes a somewhat regular grid from partial()
temp_breaks <- sort(unique(pdp_2d_hour$temp_scaled))
hum_breaks <- sort(unique(pdp_2d_hour$hum_scaled))

# A more robust way to set width/height if grid isn't perfectly uniform
# or if there are few unique values.
tile_width <- if (length(temp_breaks) > 1) mean(diff(temp_breaks)) else (if(length(temp_breaks)==1) 1 else 0)
tile_height <- if (length(hum_breaks) > 1) mean(diff(hum_breaks)) else (if(length(hum_breaks)==1) 1 else 0)

# Ensure non-zero width/height if only one break point (though partial should give a grid)
if(tile_width == 0 && length(temp_breaks) > 0) tile_width <- diff(range(model_data_hour_sample$temp_scaled, na.rm = TRUE))/10 
if(tile_height == 0 && length(hum_breaks) > 0) tile_height <- diff(range(model_data_hour_sample$hum_scaled, na.rm = TRUE))/10 


plot_2d_pdp_hour <- ggplot(pdp_2d_hour, aes(x = temp_scaled, y = hum_scaled, fill = yhat)) +
  geom_tile(width = tile_width, height = tile_height) +
  scale_fill_viridis_c(name = "Predicted Bike Count (cnt)") +
  geom_rug(data = model_data_hour_sample, aes(x = temp_scaled, y = NULL), sides = "b", alpha = 0.1, inherit.aes = FALSE) +
  geom_rug(data = model_data_hour_sample, aes(x = NULL, y = hum_scaled), sides = "l", alpha = 0.1, inherit.aes = FALSE) +
  xlab("Temperature (Scaled)") +
  ylab("Humidity (Scaled)") +
  ggtitle("2D PDP: Temperature vs. Humidity for Bike Rentals") +
  theme_minimal()

print(plot_2d_pdp_hour)
```

### Exercise 3: PDP to explain the price of a house (kc_house_data.csv)

```{r}
# Load data
house_data_full <- read_csv("data/kc_house_data.csv")

# Select relevant features and target
# Features for PDP: bedrooms, bathrooms, sqft_living, floors
# Other features for model: sqft_lot, yr_built (as per task description)
model_features_house <- c(
  "price", "bedrooms", "bathrooms", "sqft_living",
  "sqft_lot", "floors", "yr_built"
  # Consider adding other potentially relevant features like:
  # "waterfront", "view", "condition", "grade", "sqft_above", "sqft_basement"
  # For now, sticking to the explicitly mentioned ones for the model.
)
model_data_house_processed <- house_data_full %>%
  select(all_of(model_features_house)) %>%
  mutate( # Ensure numeric types where appropriate
    bedrooms = as.numeric(bedrooms),
    bathrooms = as.numeric(bathrooms),
    floors = as.numeric(floors)
    # yr_built is already numeric
  )

# Handle missing values
print(paste("Missing values in model_data_house_processed:", sum(is.na(model_data_house_processed))))
model_data_house_processed <- na.omit(model_data_house_processed)
```


```{r}
# Random sampling (as proposed: 5000 rows)
set.seed(SEED) # for reproducibility
sample_size_house <- 5000
if (nrow(model_data_house_processed) > sample_size_house) {
  model_data_house_sample <- model_data_house_processed %>% sample_n(sample_size_house)
} else {
  model_data_house_sample <- model_data_house_processed
}

```



### Fit random forest

```{r}
set.seed(SEED)
rf_model_house <- ranger(
  formula = price ~ .,
  data = model_data_house_sample,
  num.trees = 500,
  importance = 'permutation'
)
print(rf_model_house)

```

### Generate and visualize 1D PDPs


```{r}
features_to_plot_house <- c("bedrooms", "bathrooms", "sqft_living", "floors")

# Generate and plot PDPs for House Data
for (feature in features_to_plot_house) {
  cat("Processing house feature:", feature, "\n") # For debugging

  # Generate partial dependence data
  pdp_obj_house <- NULL # Initialize
  tryCatch({
    pdp_obj_house <- partial(rf_model_house,
                             pred.var = feature,
                             plot = FALSE, # We want data
                             train = model_data_house_sample,
                             # For continuous variables like sqft_living,
                             # you might want to control the grid:
                             # grid.resolution = 30, # or
                             # quantiles = TRUE, n.ice = 50 # if you want ICE-like behavior for PDP
                             # For now, using defaults which should be fine for these features
                             )
    cat("Successfully created pdp_obj_house for", feature, "\n")
    # print(head(pdp_obj_house)) # Optional: inspect
  }, error = function(e) {
    cat("Error in partial() for house feature", feature, ":", e$message, "\n")
  })

  if (!is.null(pdp_obj_house)) {
    p_house <- NULL # Initialize
    tryCatch({
      # Try autoplot first
      p_house <- autoplot(pdp_obj_house, rug = TRUE, train = model_data_house_sample) +
        ylab("Predicted House Price") +
        ggtitle(paste("PDP for", feature)) +
        theme_minimal()
      print(p_house)
      cat("Successfully plotted with autoplot for house feature", feature, "\n")
    }, error = function(e_autoplot) {
      cat("Error using autoplot for house feature", feature, ":", e_autoplot$message, "\n")
      cat("Attempting with plotPartial as a fallback for house feature", feature, "...\n")
      
      plot_base_house <- NULL
      tryCatch({
          plot_base_house <- plotPartial(pdp_obj_house, rug = TRUE, train = model_data_house_sample)
          if (inherits(plot_base_house, "ggplot")) {
              p_house <- plot_base_house +
                ylab("Predicted House Price") +
                ggtitle(paste("PDP for", feature)) +
                theme_minimal()
              print(p_house)
              cat("Successfully plotted with plotPartial for house feature", feature, "\n")
          } else {
              cat("plotPartial did not return a ggplot object for house feature", feature, ". Class was:", class(plot_base_house), "\n")
          }
      }, error = function(e_plotpartial) {
          cat("Error in plotPartial() for house feature", feature, ":", e_plotpartial$message, "\n")
      })
    })
  } else {
    cat("Skipping plot for house feature", feature, "due to error in partial().\n")
  }
  cat("------------------------------------\n") # Separator
}

```




### Questions to use in the report to analyse the influence of bedrooms, bathrooms, sqft_living and floors on the predicted price.

- Bedrooms: Does price generally increase with more bedrooms? Is there a point of diminishing returns or even a decrease (e.g., too many small bedrooms)?

- Bathrooms: Similar to bedrooms, how does the number of bathrooms affect price?

- Sqft_living: This is likely a strong driver. Is the relationship linear, or does it show non-linearities?

- Floors: How does the number of floors influence price? Does it depend on other factors (though PDP shows marginal effect)?







