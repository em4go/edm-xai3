---
title: "xAI 3"
author:
  - name: "Laiqian Ji"
  - name: "Ernesto Martínez"
  - name: "Álvaro Prado Expóstio"
format: html
---

# XAI: Interpretable Models 3

```{r}
library(readr)
library(dplyr)
library(lubridate)
library(ranger) # For Random Forest
library(pdp)    # For Partial Dependence Plots
library(ggplot2) # For plotting

SEED <- 1234 # Set seed for reproducibility
```


## Exercise 1: One-dimensional Partial Dependence Plot (Bike Rentals - day.csv)

### Loading and preprocessing

We'll use slightly the same preprocessing as in the previous xAI task for the bike rentals dataset.

```{r}
# Load data
bike_data_day <- read_csv("data/day.csv")

# Preprocessing (based on your script)
bike_data_day <- bike_data_day %>%
  mutate(
    spring = ifelse(season == 1, 1, 0),
    summer = ifelse(season == 2, 1, 0),
    fall = ifelse(season == 3, 1, 0)
  )

bike_data_day <- bike_data_day %>%
  mutate(
    MISTY = ifelse(weathersit == 2, 1, 0),
    RAIN = ifelse(weathersit %in% c(3, 4), 1, 0) # Assuming 4 is also bad weather
  )

bike_data_day <- bike_data_day %>%
  mutate(
    temp_scaled = temp * 41,       # Actual temperature in Celsius
    hum_scaled = hum * 100,        # Actual humidity in %
    windspeed_scaled = windspeed * 67 # Actual windspeed
  )

bike_data_day <- bike_data_day %>%
  mutate(
    dteday = as.Date(dteday),
    days_since_2011 = as.numeric(difftime(dteday, as.Date("2011-01-01"), units = "days"))
  )

# Select features for the model
# Note: We use the scaled versions of temp, hum, windspeed for easier interpretation
model_data_day <- bike_data_day %>%
  select(
    cnt, workingday, holiday, spring, summer, fall, MISTY, RAIN,
    temp_scaled, hum_scaled, windspeed_scaled, days_since_2011
  )

# Convert logicals/numerics that should be factors (if any, for RF)
# For ranger, it can often handle numeric 0/1s, but explicit factors can be clearer.
# For simplicity here, we'll let ranger handle them.
# Ensure no missing values, or handle them (e.g., imputation)
print(paste("Missing values in model_data_day:", sum(is.na(model_data_day))))
model_data_day <- na.omit(model_data_day) # Simple NA removal

```

### Fit random forest model


```{r}
# Fit Random Forest model
# Using ranger for efficiency. Using default mtry and 500 trees.
set.seed(SEED) # for reproducibility
rf_model_day <- ranger(
  formula = cnt ~ .,
  data = model_data_day,
  num.trees = 500,
  importance = 'permutation' # Good to have for general feature importance
)

print(rf_model_day)
```

### Generate and Visualize 1D PDPs

We'll generate PDPs for days_since_2011, temp_scaled, hum_scaled, and windspeed_scaled.


```{r}
# Features for PDP
features_to_plot_day <- c("days_since_2011", "temp_scaled", "hum_scaled", "windspeed_scaled")

# Generate and plot PDPs
for (feature in features_to_plot_day) {
  cat("Processing feature:", feature, "\n") # For debugging

  # Generate partial dependence data
  pdp_obj <- NULL # Initialize to ensure it's fresh each iteration
  tryCatch({
    pdp_obj <- partial(rf_model_day,
                       pred.var = feature,
                       plot = FALSE, # Important: we want data, not an immediate plot
                       train = model_data_day)
    cat("Successfully created pdp_obj for", feature, "\n")
    # print(head(pdp_obj)) # Optional: uncomment to inspect pdp_obj
  }, error = function(e) {
    cat("Error in partial() for feature", feature, ":", e$message, "\n")
  })

  if (!is.null(pdp_obj)) {
    # Try plotting using autoplot first
    p <- NULL # Initialize p
    tryCatch({
      # autoplot is often more robust for pdp objects
      p <- autoplot(pdp_obj, rug = TRUE, train = model_data_day) +
        ylab("Predicted Bike Count (cnt)") +
        ggtitle(paste("PDP for", feature)) +
        theme_minimal() # Added a theme for better default appearance
      print(p)
      cat("Successfully plotted with autoplot for", feature, "\n")
    }, error = function(e_autoplot) {
      cat("Error using autoplot for feature", feature, ":", e_autoplot$message, "\n")
      cat("Attempting with plotPartial as a fallback...\n")
      # Fallback to plotPartial if autoplot fails, but isolate its call
      plot_base <- NULL
      tryCatch({
          plot_base <- plotPartial(pdp_obj, rug = TRUE, train = model_data_day)
          # Check if plot_base is a ggplot object
          if (inherits(plot_base, "ggplot")) {
              p <- plot_base +
                ylab("Predicted Bike Count (cnt)") +
                ggtitle(paste("PDP for", feature)) +
                theme_minimal()
              print(p)
              cat("Successfully plotted with plotPartial for", feature, "\n")
          } else {
              cat("plotPartial did not return a ggplot object for", feature, ". Class was:", class(plot_base), "\n")
          }
      }, error = function(e_plotpartial) {
          cat("Error in plotPartial() for feature", feature, ":", e_plotpartial$message, "\n")
      })
    })
  } else {
    cat("Skipping plot for", feature, "due to error in partial().\n")
  }
  cat("------------------------------------\n") # Separator
}
```



## Exercise 2: Bidimensional Partial Dependency Plot (Bike Rentals - hour.csv)

### Data loading and preprocessing

```{r}
bike_data_hour_full <- read_csv("data/hour.csv")

# Preprocessing
# Scale temp, hum, windspeed similar to day.csv for consistency
# Original values in hour.csv for temp, atemp, hum, windspeed are normalized (0-1)
bike_data_hour_processed <- bike_data_hour_full %>%
  mutate(
    temp_scaled = temp * 41,       # Actual temperature in Celsius
    hum_scaled = hum * 100,        # Actual humidity in %
    windspeed_scaled = windspeed * 67, # Actual windspeed
    # Create categorical season and weather if needed for the model,
    # or use them as is if ranger handles them well.
    # For PDP, we only need temp_scaled, hum_scaled, and other predictors.
    season = factor(season),
    weathersit = factor(weathersit),
    holiday = factor(holiday),
    workingday = factor(workingday),
    weekday = factor(weekday),
    yr = factor(yr) # yr is 0 or 1, can be a factor or numeric
  )

# Select features for the model.
# Include relevant features that might influence bike count.
model_features_hour <- c(
    "cnt", "season", "yr", "mnth", "hr", "holiday", "weekday",
    "workingday", "weathersit", "temp_scaled", "hum_scaled", "windspeed_scaled"
)
model_data_hour_processed <- bike_data_hour_processed %>%
  select(all_of(model_features_hour))

# Handle missing values (if any)
print(paste("Missing values in model_data_hour_processed:", sum(is.na(model_data_hour_processed))))
model_data_hour_processed <- na.omit(model_data_hour_processed)
```

### Random sampling to reduce the amount of data (2000 rows)

```{r}
model_data_hour_processed
```



```{r}
set.seed(SEED) # for reproducibility
sample_size_hour <- 2000
n_total_rows_hour <- nrow(model_data_hour_processed)

if (n_total_rows_hour > sample_size_hour) {
  # Determine the latest possible starting point for a contiguous block
  max_start_index <- n_total_rows_hour - sample_size_hour + 1

  # Randomly select a starting index for the block
  # Ensure max_start_index is at least 1
  if (max_start_index < 1) {
      max_start_index <- 1 # Should not happen if n_total_rows_hour > sample_size_hour
  }
  start_index <- sample(1:max_start_index, 1)

  # Extract the contiguous block of rows
  model_data_hour_sample <- model_data_hour_processed[start_index:(start_index + sample_size_hour - 1), ]

  cat("Sampled a contiguous block of", sample_size_hour, "rows, starting at index", start_index, "\n")
  cat("Time range of sample (based on first and last 'instant' if available, or row numbers):\n")
  # If you have 'dteday' and 'hr' in model_data_hour_sample, you can print their range
  # For example, if 'instant' is still in bike_data_hour_full and corresponds to rows:
  # first_instant_in_sample <- bike_data_hour_full$instant[start_index]
  # last_instant_in_sample <- bike_data_hour_full$instant[start_index + sample_size_hour - 1]
  # cat("Instant range:", first_instant_in_sample, "to", last_instant_in_sample, "\n")

} else {
  # If the total number of rows is less than or equal to the sample size, use all data
  model_data_hour_sample <- model_data_hour_processed
  cat("Using all", n_total_rows_hour, "rows as sample size is not smaller.\n")
}

# Verify the dimensions of the sample
print(dim(model_data_hour_sample))
```



















